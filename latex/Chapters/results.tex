%!TEX root = ../msc_thesis.tex

\chapter{Experimental results}
\label{ch:results}

In this section, the results of the experiments run are shown. Everything was done in Keras using Tensorflow as backend and mainly through R, although some Python code was used via the \texttt{reticulate} package.

\section{MNIST dataset}

The first goal was to replicate \citeauthor{Gal2016Active}'s work done with MNIST dataset in \citetitle{Gal2016Active}. The results can be seen in figure \ref{fig:mnist_comparison_active_learning_random}, where I compare my results (on the left) with the original paper's results (right). The results are pretty similar overall, although the mean STD acquisition function was not implemented in the replication due to the bad performance shown in the paper.

Even when my implementation achieved the goal of outperforming a random acquisition function, when comparing Bayesian and frequentist approaches the results differ. The paper's authors claim that the use of a Bayesian approach in the acquisition process of Active Learning leads to better accuracy with fewer images, but in my implementation there is virtually no distinction between both approaches. This can be seen in figures in \ref{fig:mnist_pred_entropy_AL} and \ref{fig:mnist_var_ratios_AL} that show my results (left) and the paper's authors results (right). In the paper, the frequentist acquisition functions show a worse performance than their Bayesian counterparts, but in my implementation there is no distinction. For example, with predictive entropy in figure \ref{fig:mnist_pred_entropy_AL}, the frequentist acquisition function in the original paper achieve a 90\% accuracy with around 300 images, while in my implementation this accuracy is first achieved with around 200 images.


\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{mnist_bayesian_accuracy.png}
    \caption{Accuracy of models in each acquisition step. The left picture shows my implementation and the right picture shows \citeauthor{Gal2016Active}'s implementation.}
    \label{fig:mnist_comparison_active_learning_random}
\end{figure}

\begin{figure}[H]
  \centering
  \subfloat[My results.]{\includegraphics[width=0.5\textwidth]{mnist_pred_entropy_mine.png}}
  \hfill
  \subfloat[Paper's results.]{\includegraphics[width=0.5\textwidth]{mnist_pred_entropy_islam.png}}
  \caption{Accuracy of Bayesian and frequentist models in each acquisition step using predictive entropy as acquisition function. The left picture shows my implementation and the right picture shows \citeauthor{Gal2016Active}'s implementation.}
  \label{fig:mnist_pred_entropy_AL}
\end{figure}


\begin{figure}[H]
  \centering
  \subfloat[My results.]{\includegraphics[width=0.5\textwidth]{mnist_var_ratio_mine.png}}
  \hfill
  \subfloat[Paper's results.]{\includegraphics[width=0.5\textwidth]{mnist_var_ratio_islam.png}}
  \caption{Accuracy of Bayesian and frequentist models in each acquisition step using variation ratios as acquisition function. The left picture shows my implementation and the right picture shows \citeauthor{Gal2016Active}'s implementation.}
  \label{fig:mnist_var_ratios_AL}
\end{figure}

One more thing that should be mentioned is that I could not implement the BALD acquisition in the frequentist setting because of the way it is defined. The BALD uncertainty for a prediction $y$ given model parameters $\mathcal{W}$, features $x$ and training data $\mathcal{D}$ is defined as

\begin{equation}
	\label{eq:bald_def}
	\mathbb{I}[y, \mathcal{W} | x, \mathcal{D}] = \mathbb{H}[y | x, \mathcal{D}] - \mathbb{E}_{p(\mathcal{W} | \mathcal{D})}[\mathbb{H}[y | x, \mathcal{W}]]
\end{equation}

with $\mathbb{H}[y | x, \mathcal{D}]$ is the predictive entropy and is defined as $-\sum_c p(y = c | x, \mathcal{D}) \log p(y = c | x, \mathcal{D})$. In the Bayesian case, we have a set of $T$ dropout samples that approximate the predictive distribution, so the second part of equation \ref{eq:bald_def}, i.e., the expected value $\mathbb{E}_{p(\mathcal{W} | \mathcal{D})}[\mathbb{H}[y | x, \mathcal{W}]]$ is approximated by averaging the predictive entropy of each predictive sample; this way $\mathbb{I}[y, \mathcal{W} | x, \mathcal{D}]$ is computed by taking the difference of this quantity and the first part of equation \ref{eq:bald_def}. In the frequentist case, we only have one point estimate, so that difference is zero, so $\mathbb{I}[y, \mathcal{W} | x, \mathcal{D}]$ is zero for all points in the pool set. To this day, I don't know how the paper's authors computed it because their Github code is not clear and they haven't answered my email where I asked them that.

\section{Cats and dogs dataset}


\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{cats_dogs_accuracy.png}
    \caption{Accuracy of models in each acquisition step in the cats and dogs dataset.}
    \label{fig:cats_dogs_comparison_active_learning_random}
\end{figure}


\section{CIFAR10 dataset}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{cifar10_accuracy.png}
    \caption{Accuracy of models in each acquisition step in the CIFAR10 dataset.}
    \label{fig:cifar10_comparison_active_learning_random}
\end{figure}

\section{Discussion}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{probs_iterations.png}
    \caption{Probabilities of each model in each acquisition iteration.}
    \label{fig:probs_iterations}
\end{figure}
