%!TEX root = ../msc_thesis.tex

\chapter{Experimental results}
\label{ch:results}

In the previous chapters, the theory of different subjects was presented, including machine learning, ANNs, active learning, Bayesian statistics, variational inference, and how they are all related. In this chapter, the results of a series of experiments with three different data sets are shown. These datasets are the MNIST dataset \cite{lecun1998gradient}, the CIFAR-10 dataset \cite{krizhevsky2009learning}, and a dataset of cat and dog pictures \cite{elson2007asirra}.

In all experiments, a deep convolutional network was trained to classify the images in each data set. The experiment setup was very similar to the one in chapter \ref{ch:active_learning} in the sense that each model was trained with an initial small random set of images, and then an acquisition function was used to select new images from a pool set $\mathcal{U}$ so that they would be added to the training set $mathcal{L}$ and a new model would be trained with this new bigger data set of labeled images.

Six acquisition functions were used: Bayesian predictive entropy, frequentist predictive entropy, Bayesian variation ratios, frequentist variation ratios, BALD, and random. The Bayesian CNNs were created using the dropout variational approximation mentioned in chapter \ref{ch:ann}.

All models were trained using Keras\cite{chollet2015keras} with Tensorflow \cite{tensorflow2015-whitepaper} as backend. Most of the code is in R with some Python scripts called from R using the \texttt{reticulate} package \cite{reticulate_package}.

\section{MNIST dataset}

The MNIST dataset is a collection of images representing \numprint{70000} handwritten digits

The first goal was to replicate \citeauthor{Gal2016Active}'s work done with MNIST dataset in \citetitle{Gal2016Active}. The results can be seen in figure \ref{fig:mnist_comparison_active_learning_random}, where I compare my results (on the left) with the original paper's results (right). The results are pretty similar overall, although the mean STD acquisition function was not implemented in the replication due to the bad performance shown in the paper.

Even when my implementation achieved the goal of outperforming a random acquisition function, when comparing Bayesian and frequentist approaches the results differ. The paper's authors claim that the use of a Bayesian approach in the acquisition process of Active Learning leads to better accuracy with fewer images, but in my implementation there is virtually no distinction between both approaches. This can be seen in figures in \ref{fig:mnist_pred_entropy_AL} and \ref{fig:mnist_var_ratios_AL} that show my results (left) and the paper's authors results (right). In the paper, the frequentist acquisition functions show a worse performance than their Bayesian counterparts, but in my implementation there is no distinction. For example, with predictive entropy in figure \ref{fig:mnist_pred_entropy_AL}, the frequentist acquisition function in the original paper achieve a 90\% accuracy with around 300 images, while in my implementation this accuracy is first achieved with around 200 images.


\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{mnist_bayesian_accuracy.png}
    \caption{Accuracy of models in each acquisition step. The left picture shows my implementation and the right picture shows \citeauthor{Gal2016Active}'s implementation.}
    \label{fig:mnist_comparison_active_learning_random}
\end{figure}

\begin{figure}[H]
  \centering
  \subfloat[My results.]{\includegraphics[width=0.5\textwidth]{mnist_pred_entropy_mine.png}}
  \hfill
  \subfloat[Paper's results.]{\includegraphics[width=0.5\textwidth]{mnist_pred_entropy_islam.png}}
  \caption{Accuracy of Bayesian and frequentist models in each acquisition step using predictive entropy as acquisition function. The left picture shows my implementation and the right picture shows \citeauthor{Gal2016Active}'s implementation.}
  \label{fig:mnist_pred_entropy_AL}
\end{figure}


\begin{figure}[H]
  \centering
  \subfloat[My results.]{\includegraphics[width=0.5\textwidth]{mnist_var_ratio_mine.png}}
  \hfill
  \subfloat[Paper's results.]{\includegraphics[width=0.5\textwidth]{mnist_var_ratio_islam.png}}
  \caption{Accuracy of Bayesian and frequentist models in each acquisition step using variation ratios as acquisition function. The left picture shows my implementation and the right picture shows \citeauthor{Gal2016Active}'s implementation.}
  \label{fig:mnist_var_ratios_AL}
\end{figure}


% One more thing that should be mentioned is that I could not implement the BALD acquisition in the frequentist setting because of the way it is defined. The BALD uncertainty for a prediction $y$ given model parameters $\mathcal{W}$, features $x$ and training data $\mathcal{D}$ is defined as
%
% \begin{equation}
% 	\label{eq:bald_def}
% 	\mathbb{I}[y, \mathcal{W} | x, \mathcal{D}] = \mathbb{H}[y | x, \mathcal{D}] - \mathbb{E}_{p(\mathcal{W} | \mathcal{D})}[\mathbb{H}[y | x, \mathcal{W}]]
% \end{equation}
%
% with $\mathbb{H}[y | x, \mathcal{D}]$ is the predictive entropy and is defined as $-\sum_c p(y = c | x, \mathcal{D}) \log p(y = c | x, \mathcal{D})$. In the Bayesian case, we have a set of $T$ dropout samples that approximate the predictive distribution, so the second part of equation \ref{eq:bald_def}, i.e., the expected value $\mathbb{E}_{p(\mathcal{W} | \mathcal{D})}[\mathbb{H}[y | x, \mathcal{W}]]$ is approximated by averaging the predictive entropy of each predictive sample; this way $\mathbb{I}[y, \mathcal{W} | x, \mathcal{D}]$ is computed by taking the difference of this quantity and the first part of equation \ref{eq:bald_def}. In the frequentist case, we only have one point estimate, so that difference is zero, so $\mathbb{I}[y, \mathcal{W} | x, \mathcal{D}]$ is zero for all points in the pool set. To this day, I don't know how the paper's authors computed it because their Github code is not clear and they haven't answered my email where I asked them that.

\section{Cats and dogs dataset}


\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{cats_dogs_accuracy.png}
    \caption{Accuracy of models in each acquisition step in the cats and dogs dataset.}
    \label{fig:cats_dogs_comparison_active_learning_random}
\end{figure}


\section{CIFAR-10 dataset}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{cifar10_accuracy.png}
    \caption{Accuracy of models in each acquisition step in the CIFAR-10 dataset.}
    \label{fig:cifar10_comparison_active_learning_random}
\end{figure}

\section{Discussion}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{probs_iterations.png}
    \caption{Probabilities of each model in each acquisition iteration.}
    \label{fig:probs_iterations}
\end{figure}
