%!TEX root = ../msc_thesis.tex

\chapter{Active Learning}
\label{ch:active_learning}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% AL
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \section{Active Learning}

An active learning problem is one in which the learner is able to select its own training data so that the performance will be better with less training data. This is attractive because many times, labeled data is expensive or hard to acquire, hence the desire to use the available labeled data as efficiently as possible.

For example, a modeler may have access to a lot of unlabeled data points and few labeled data points. These labeled data points may be expensive to label by human annotators, and they also may be used in a supervised learning problem, but it is desirable to somehow take advantage of the unlabeled data. An active learning task would be to train a model $\hat{f}$ with an initial set of labeled data $\mathcal{D}$. Afterwards, the model (the learner) could choose new data points $\boldsymbol{x}^*$ from a pool of unlabeled data $\mathcal{U}$, to ask to an \textit{oracle} (e.g., a human annotator) what the corresponding output $y^*$ is, and finally add the pair $(\boldsymbol{x}^*, {y}^*)$ to the training data. This process would be repeated until certain criteria are met, with the training set increasing in size with each iteration.

Figure \ref{fig:Active_Learning_Cycle} shows this cycle in a diagram. The main goal of active learning is to select which $\boldsymbol{x}^*$ to incorporate to the training data \cite{cohn1996active}. In the end, it is expected that this procedure leads to a better predictive performance than randomly selecting new observations to add to the training data.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{Active_Learning_Cycle}
    \caption{Active learning cycle. A model is trained from the labeled data $\mathcal{D}$, data points are taken from the unlabeled pool of data $\mathcal{U}$, labeled by an oracle and then added to the training set of labeled data $\mathcal{D}$ in order to retrain the model and continue the cycle. Image taken from \cite{settles.tr09}.}
    \label{fig:Active_Learning_Cycle}
\end{figure}

The type of active learning described in the previous example, in which there is a large collection of unlabeled data $\mathcal{U}$ and a small set of labeled data $\mathcal{D}$, is called \textit{pool-based sampling}. Pool-based sampling will be the main focus of this work. There are other types of active learning but, since they are not of interest to this work, they will not be discussed. However, \cite{olsson2009literature} and \cite{settles.tr09} provide a good overview of these techniques and reference to more sources of information.

As mentioned before, in pool-based sampling, a model is trained with labeled training data from $\mathcal{D}$, and then, new data points are chosen to be labeled from the unlabeled data pool $\mathcal{U}$. The new data points are chosen using an \textbf{acquisition function} $a(x, \hat{f})$
that proposes candidates given a specific criterion. For example, the model's prediction uncertainty can be used to select new unlabeled data points. Usually, one would like to explore the feature space where uncertainty is higher as this corresponds to providing the learner the most informative feature. Also, some other entropy-based methods can be used. The new observation $\boldsymbol{x}^*$ is chosen so that it maximizes the acquisition function of all the observations in the pool set. The role of the acquisition function is to evaluate the gain of information of each unlabeled data point.

The acquisition functions that will be used and compared in this work are four, three of which use the posterior predictive distribution. Particularly, the posterior predictive probability of an observation $\boldsymbol{x}^*$ having a label $y^*$ belonging to a class $c$, denoted as $p(y^* = c | \boldsymbol{X}, \boldsymbol{y}, \boldsymbol{x}^*)$. Because of the definition of these acquisition functions, they only work in classification problems. The four acquisition functions are the following:

\begin{enumerate}
  \item Predictive entropy:

  $\mathbb{H} \left[ y^* | \boldsymbol{X}, \boldsymbol{y}, \boldsymbol{x}^* \right] = - \sum_c p(y^* = c | \boldsymbol{X}, \boldsymbol{y}, \boldsymbol{x}^*) \log p(y^* = c | \boldsymbol{X}, \boldsymbol{y}, \boldsymbol{x}^*)$.

  \item Variation ratios: $1 - \max_y p(y^* | \boldsymbol{X}, \boldsymbol{y}, \boldsymbol{x}^*)$.

  \item Bayesian Active Learning by Disagreement (BALD):

  $\mathbb{H} \left[ y^* | \boldsymbol{X}, \boldsymbol{y}, \boldsymbol{x}^* \right] - \mathbb{E}_{p(\boldsymbol{\theta} | \boldsymbol{X}, \boldsymbol{y})} \left[ \mathbb{H} \left[ y^* | \boldsymbol{x}^*, \boldsymbol{\theta} \right] \right]$.

  \item Random: Choosing an observation uniformly random from the pool of unlabeled data $\mathcal{U}$.

\end{enumerate}

Note that predictive entropy and variation ratios can be used with a frequentist classifier because instead of using the posterior predictive distribution, one can use the predicted probability of each class. The BALD acquisition function, however, can only be used with a Bayesian classifier because in the case of a frequentist classifier, the result of this function is always zero. This is easy to see given the definition of the acquisition function
\begin{equation}
	\label{eq:bald_acq_func_def}
	% \mathbb{I}[y^*, \mathcal{W} | x, \mathcal{D}] =
  \mathbb{H} \left[ y^* | \boldsymbol{X}, \boldsymbol{y}, \boldsymbol{x}^* \right] -
    \mathbb{E}_{p(\boldsymbol{\theta} | \boldsymbol{X}, \boldsymbol{y})} \left[ \mathbb{H} \left[ y^* | \boldsymbol{x}^*, \boldsymbol{\theta} \right] \right],
\end{equation}
where $\mathbb{H} \left[ y^* | \boldsymbol{X}, \boldsymbol{y}, \boldsymbol{x}^* \right]$ is the predictive entropy, previously defined as
\begin{equation}
	\label{eq:entropy_acq_func_def}
  \mathbb{H} \left[ y^* | \boldsymbol{X}, \boldsymbol{y}, \boldsymbol{x}^* \right] = - \sum_c p(y^* = c | \boldsymbol{X}, \boldsymbol{y}, \boldsymbol{x}^*) \log p(y^* = c | \boldsymbol{X}, \boldsymbol{y}, \boldsymbol{x}^*).
\end{equation}

In the Bayesian case, one has a positive number of samples from the posterior predictive distribution, so the second part of equation \eqref{eq:bald_acq_func_def}, i.e., the expected value
$\mathbb{E}_{p(\boldsymbol{\theta} | \boldsymbol{X}, \boldsymbol{y})} \left[ \mathbb{H} \left[ y^* | \boldsymbol{x}^*, \boldsymbol{\theta} \right] \right]$
is approximated by averaging the predictive entropy of each predictive sample. This way, the BALD acquisition function is computed by taking the difference of this quantity and the first part of equation \eqref{eq:bald_acq_func_def}.
In the frequentist case, there is only one point estimate, so that difference is zero, hence the BALD acquisition function is always zero.

If the data points in the pool of unlabeled data points $\mathcal{U}$ are in random order, then using BALD as an acquisition function with a frequentist classifier is equivalent to a random acquisition function because all data points in $\mathcal{U}$ have the same acquisition function value.

A simple example of the active learning cycle was implemented in the R programming language. This figure summarizes the results of a two class classification problem using a frequentist logistic regression model and the variation ratios acquisition function. Similarly to what was done in Chapter \ref{ch:machine_learning}, a data set was generated with a data matrix $\boldsymbol{X} \in \mathbb{R}^{n \times 10}$ with $n = 1000$ such that $\boldsymbol{x_i^{(k)}} \sim N(0, 1)$ for each $i \in \left\{1, ..., n \right\}$ and $k \in \left\{1, ..., 10 \right\}$.
Then an auxiliary vector was computed, $p_i = \frac{1}{1 + \exp \left( - \sum_{k = 1}^{10} \theta_k x_i^{(k)}  \right)}$, with each $\theta_k$ sampled from a continuous uniform distribution from -5 to 5. Finally, the response variable $\boldsymbol{y}$ was built simulating Bernoulli random variables such that $y_i \sim \mathrm{Bern}(p_i)$.

For the example, an initial random training set of 20 observations $\mathcal{D}$ was generated, with 10 examples of each class. Of the 980 points that were not used, 300 were used as a validation set, and the remaining 680 points were used as the unlabeled pool set $\mathcal{U}$.
Then, 180 acquisition iterations were made, in each iteration training a new logistic regression model, making predictions on the pool set $\mathcal{U}$, and using these predictions to compute the frequentist variation ratios and to choose the data point with the highest value so that it would be added to the training set set $\mathcal{D}$. In order to remove sampling noise, this process was repeated 50 times, each time choosing different initial random training, validation and pool sets. The same was done using a random acquisition function to compare with the active learning setting.

Figure \ref{fig:log_reg_AL_accuracies_plot} shows the mean accuracy on the validation set in each acquisition iteration, with the light colors showing the 25-th and 75-th percentiles of the accuracies in each iteration. It is clear that using active learning leads to a better performance of the model with less data compared to a random sample from $\mathcal{U}$.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{log_reg_AL_accuracies_plot}
    \caption{Accuracies of a logistic regression model using a variation ratios acquisition function (blue) and a random acquisition function (red).}
    \label{fig:log_reg_AL_accuracies_plot}
\end{figure}

To see what kind of points the acquisition function chooses, another example was implemented. This example is very similar to the last one, but in this case the parameter vector $\boldsymbol{\theta}$ is a two-dimensional vector such that $\boldsymbol{\theta} = \left[ 1, 1 \right]^T$. Again, 1000 points were generated and an initial random training set of 10 training examples (5 of each class) was randomly chosen from these 1000 points. This was followed by 70 active learning iterations, using both a variation ratios acquisition function and a random acquisition function.

Figure \ref{fig:log_reg_AL_decision_boundary_plot} shows the results of this process. On the left, the generated data are shown, with the thin black line representing the real decision boundary of the generated data. The center image highlights the data points selected by the random acquisition function. Again, the thin black line is the real decision boundary, whilst the bold dashed black line is the decision boundary of the trained model. The right image highlights the data points selected by the variation ratios acquisition function, where the black lines represent the same as in the center image. It can be seen that when using the variation ratios acquisition function, the selected data points lie close to the decision boundary, whilst using the random acquisition function, points from all the domain are chosen. This is because points lying close to the decision boundary give more information than points in the outer parts of the quadrant. In the end, the variation ratios acquisition function helped choose the points that lead to a better approximation to the real decision boundary.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{log_reg_AL_decision_boundary_plot}
    \caption{Comparison of points chosen by a random acquisition function and a variation ratios acquisition function.}
    \label{fig:log_reg_AL_decision_boundary_plot}
\end{figure}

This chapter provided a brief introduction to pool-based active learning and four acquisition functions. Chapter \ref{ch:results} will show different implementations of active learning problems using Convolutional Neural Networks and different acquisition functions. It will also compare the predictive performance of these acquisition functions in three different data sets.
